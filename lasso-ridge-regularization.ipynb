# -*- coding: utf-8 -*-
"""
Created on Tue Jun 24 17:46:03 2025

@author: DELL
"""


# import numirical libraries
import pandas as pd
import numpy as np 
 
 # import graphical plotting libraries
import seaborn as sns 
import matplotlib.pyplot as plt 
%matplotlib inline
  
# import linear regression machine learning libraries
from sklearn import preprocessing
from sklearn.preprocessing import PolynomialFeatures
from sklearn.model_selection import train_test_split

from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.metrics import r2_score

# data import
data = pd.read_csv(r"C:\Users\DELL\Downloads\car-mpg.csv")
data
data.head()


# drop car name 
# replace  origin into 1,2,3,... dont forget dummies 
# replace with nan
# replace all nan with median


data = data.drop(['car_name'],axis = 1)
data['origin'] = data['origin'].replace({1:'america', 2:'europe', 3:'asia'})

data = data.replace('?',np.nan)
data = data.apply(lambda x: x.fillna(x.median()), axis = 0)
data.head()

 ##  2. model building
 
 X = data.drop(['mpg'], axis = 1) # independent veriable
 y = data[['mpg']]  # dependent variable
 
 # scaling the data 
from sklearn import preprocessing
import numpy as np

x = np.array([[1, 2], [3, 4], [5, 6]])
x_s = preprocessing.scale(x)
print(x_s)
x_s = pd.DataFrame(x_s, columns=x.columns)
y_s = preprocessing.scale(y)
y_s = pd.DataFrame(y_s, columns=y.columns)



# splite int train test set
X_train,x_test,y_train,y_test = train_test_split(x_s,y_s,test_size=0.30,random_state=1)
X_train.shape
   
   
   # 2. a simple linear model 
#  fit simple linear model and find coffieciaants
 
 regression_model = LinearRegression()
regression_model.fit(x_train, y_train)

for idx, col_name in enumerate(x_train.columns): 
    print('the coefficient for {} is{}'.format(col_name,regression_model.coef_[0][idx]))
intercept = regression_model.intercept_[0]
print('the intercept is {}'.format(intercept))    


# 2.b Regularized ridze regression

ridge_model = Ridge(alpha=0.3)
ridge_model.fit(x_train, y_train)
print("Ridge model coef:{}".format(Ridge_model.coef_))
  
  # 2.c regularized lasso regression 
 Lasso_model = Lasso(alpha=0.1)
 lasso_model.fit(x_train, y_train)
 print('lasso.model coef:{}'.format(lasso_model.coef_))

# 3. score comprison
# simple linear model
print(regression_model_score(x_train, y_train))
print(regression_model_score(x_test, y_test))
 print(**********************)

# Ridge Model --
print(ridge_model_score(x_train, y_train))
print(ridge_model_score(x_test, y_test))
print(**********************)

# lasso model--
print(lasso_model_score(x_train, y_train))
print(lasso_model_score(x_test, y_test))
print(**********************)
 
 # 4 Model Parameter tunin
data_train_test = pd.concat([x_train, y_train],axis = 1)
data_train_test.head()

import statsmodel.formula.api as smf
ols1 = smf.ols(formula = 'mpg ~ cyl+disp+hp+wt+acc+yr+car_type+origin_america+origin_europe+origin_asia', data = data_train_test).fit()
ols1.params

print(ols1.summary())

mse = np.mean((regression_model.predict(x_test)-y_test)**2)

import mata
rmse = math.sqrt(mse)
print('root mean squared error:{}'.format(rmse))

fig = plt.figure(figsize=8,6)
sns.residplot(x= X_test['hp'], y= y_test['mpg'], color='green', lowess=True )

fig = plt.figure(figsize=(8,6))
sns.residplot(x= X_test['acc'], y= y_test['mpg'], color='green', lowess=True )


y_pred = regression_model.predict(x_test)
plt.scatter(y_test["mpg"],y_pred)
